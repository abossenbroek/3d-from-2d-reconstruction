{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/abossenbroek/3d-from-2d-reconstruction/blob/main/labs/pytorch3d_intro/Deformable_mesh_rendering_on_point_cloud.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a raw point cloud on a mesh\n",
    "\n",
    "This tutorial shows how to:\n",
    "- Load a point cloud from a `.ply` file and view it\n",
    "- Fit a mesh to the point cloud\n",
    "- Use loss functions on meshes and point clouds\n",
    "- How to sample from point clouds and meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%shell \n",
    "pip install open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "need_pytorch3d = False\n",
    "try:\n",
    "    import pytorch3d\n",
    "except ModuleNotFoundError:\n",
    "    need_pytorch3d = True\n",
    "if need_pytorch3d:\n",
    "    if torch.__version__.startswith(\"1.13.\") and sys.platform.startswith(\"linux\"):\n",
    "        # We try to install PyTorch3D via a released wheel.\n",
    "        pyt_version_str = torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
    "        version_str = \"\".join(\n",
    "            [\n",
    "                f\"py3{sys.version_info.minor}_cu\",\n",
    "                torch.version.cuda.replace(\".\", \"\"),\n",
    "                f\"_pyt{pyt_version_str}\",\n",
    "            ]\n",
    "        )\n",
    "        !pip install fvcore iopath\n",
    "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
    "    else:\n",
    "        # We try to install PyTorch3D from source.\n",
    "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
    "        !tar xzf 1.10.0.tar.gz\n",
    "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
    "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Util function for loading meshes\n",
    "from pytorch3d.io import load_obj, load_objs_as_meshes, load_ply, save_obj, save_ply\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance,\n",
    "    mesh_edge_loss,\n",
    "    mesh_laplacian_smoothing,\n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.renderer import (\n",
    "    DirectionalLights,\n",
    "    FoVPerspectiveCameras,\n",
    "    Materials,\n",
    "    MeshRasterizer,\n",
    "    MeshRenderer,\n",
    "    PointLights,\n",
    "    RasterizationSettings,\n",
    "    SoftPhongShader,\n",
    "    TexturesUV,\n",
    "    TexturesVertex,\n",
    "    look_at_view_transform,\n",
    ")\n",
    "\n",
    "# Data structures and functions for rendering\n",
    "from pytorch3d.structures import Meshes, Pointclouds\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.vis.plotly_vis import AxisArgs, plot_batch_individually, plot_scene\n",
    "from pytorch3d.vis.texture_vis import texturesuv_image_matplotlib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install and Import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure `torch` and `torchvision` are installed. If `pytorch3d` is not installed, install it using the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARNING: CPU only, this will be slow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load a raw point cloud\n",
    "\n",
    "Load an `.ply` file. \n",
    "\n",
    "- load with `open3d` to allow easy access to x, y, z for plotting with `plotly`\n",
    "- plot with `plotly` as scatter plot\n",
    "- load with `pytorch3d` using `load_ply()`\n",
    "- scale and center the raw point cloud to ensure the mean is at 0 on all axis and the maximum on each axis is bounded between $[-1, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/PacktPublishing/3D-Deep-Learning-with-Python/main/chap3/pedestrian.ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.io.read_point_cloud(\"pedestrian.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the target 3D model using load_obj\n",
    "verts, faces = load_ply(\"pedestrian.ply\")\n",
    "\n",
    "point_cloud = Pointclouds(points=[verts])\n",
    "\n",
    "verts = verts.to(device)\n",
    "faces = faces.to(device)\n",
    "\n",
    "# Center around 0 and scale to [-1, 1]\n",
    "center = verts.mean(0)\n",
    "verts = verts - center\n",
    "scale = max(verts.abs().max(0)[0])\n",
    "verts = verts / scale\n",
    "verts = verts[None, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(pcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(pcd.points)[:, 0]\n",
    "y = np.asarray(pcd.points)[:, 1]\n",
    "z = np.asarray(pcd.points)[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            z=z,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=12,\n",
    "                color=z,  # set color to an array/list of desired values\n",
    "                colorscale=\"Viridis\",  # choose a colorscale\n",
    "                opacity=0.8,\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mesh prediction via optimization\n",
    "In the previous section, we created loaded our raw point cloud.\n",
    "\n",
    "Next we want to create a mesh that minimizes our losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses as a function of optimization iteration\n",
    "def plot_losses(losses):\n",
    "    fig = plt.figure(figsize=(13, 5))\n",
    "    ax = fig.gca()\n",
    "    for k, l in losses.items():\n",
    "        ax.plot(l[\"values\"], label=k + \" loss\")\n",
    "    ax.legend(fontsize=\"16\")\n",
    "    ax.set_xlabel(\"Iteration\", fontsize=\"16\")\n",
    "    ax.set_ylabel(\"Loss\", fontsize=\"16\")\n",
    "    ax.set_title(\"Loss vs iterations\", fontsize=\"16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    \"chamfer\": {\"weight\": 1.0, \"values\": []},  # Weight for the chamfer loss\n",
    "    \"edge\": {\"weight\": 1.0, \"values\": []},  # Weight of mesh edge loss\n",
    "    \"normal\": {\"weight\": 0.01, \"values\": []},  # Weight of normal consistency\n",
    "    \"laplacian\": {\"weight\": 1.0, \"values\": []},  # Weight of mesh laplacian smoothing\n",
    "}\n",
    "\n",
    "# Number of optimization steps\n",
    "Niter = 2000\n",
    "# Plot period for the losses\n",
    "plot_period = 250\n",
    "\n",
    "# SGD learning ratge\n",
    "SGD_lr = 1.0\n",
    "# SGD momentum\n",
    "SGD_momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a sphere\n",
    "src_mesh = ico_sphere(4, device)\n",
    "src_vert = src_mesh.verts_list()\n",
    "deform_verts = torch.full(src_vert[0].shape, 0.0, device=device, requires_grad=True)\n",
    "\n",
    "# The optimizer\n",
    "optimizer = torch.optim.SGD([deform_verts], lr=SGD_lr, momentum=SGD_momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define update rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes = {\"iter\": [], \"mesh\": []}\n",
    "\n",
    "\n",
    "# Losses to smooth / regularize the mesh shape\n",
    "def update_mesh_shape_prior_losses(mesh, original_points, sampled_points, loss):\n",
    "\n",
    "    loss[\"chamfer\"], _ = chamfer_distance(sampled_points, original_points)\n",
    "\n",
    "    # and (b) the edge length of the predicted mesh\n",
    "    loss[\"edge\"] = mesh_edge_loss(mesh)\n",
    "\n",
    "    # mesh normal consistency\n",
    "    loss[\"normal\"] = mesh_normal_consistency(mesh)\n",
    "\n",
    "    # mesh laplacian smoothing\n",
    "    loss[\"laplacian\"] = mesh_laplacian_smoothing(mesh, method=\"uniform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = tqdm(range(Niter))\n",
    "\n",
    "for i in loop:\n",
    "    # Initialize optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Deform the mesh\n",
    "    new_src_mesh = src_mesh.offset_verts(deform_verts)\n",
    "\n",
    "    # We sample 5k points from the surface of each mesh\n",
    "    sample_src = sample_points_from_meshes(new_src_mesh, verts.shape[1])\n",
    "\n",
    "    # Losses to smooth /regularize the mesh shape\n",
    "    loss = {k: torch.tensor(0.0, device=device) for k in losses}\n",
    "    update_mesh_shape_prior_losses(new_src_mesh, verts, sample_src, loss)\n",
    "\n",
    "    # Weighted sum of the losses\n",
    "    sum_loss = torch.tensor(0.0, device=device)\n",
    "    for k, l in loss.items():\n",
    "        sum_loss += l * losses[k][\"weight\"]\n",
    "        losses[k][\"values\"].append(float(l.detach().cpu()))\n",
    "\n",
    "    # Print the losses\n",
    "    loop.set_description(\"total_loss = %.6f\" % sum_loss)\n",
    "\n",
    "    # Optimization step\n",
    "    sum_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Store rendered meshes\n",
    "    if i % plot_period:\n",
    "        tmp_verts, temp_face = new_src_mesh.get_mesh_verts_faces(0)\n",
    "        tmp_verts_transformed = tmp_verts * scale + center\n",
    "        temp_mesh = Meshes(\n",
    "            verts=[tmp_verts_transformed.to(device)],\n",
    "            faces=[tmp_verts_transformed.to(device)],\n",
    "        )\n",
    "\n",
    "        meshes[\"iter\"].append(i)\n",
    "        meshes[\"mesh\"].append(temp_mesh)\n",
    "\n",
    "\n",
    "# Fetch the verts and faces of the final predicted mesh\n",
    "final_verts, final_faces = new_src_mesh.get_mesh_verts_faces(0)\n",
    "\n",
    "# Scale normalize back to the original target size\n",
    "final_verts = final_verts * scale + center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = Meshes(\n",
    "    verts=[final_verts.to(device)],\n",
    "    faces=[final_faces.to(device)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Show intermediate and final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the plotly figure\n",
    "plots = {}\n",
    "\n",
    "for i, m in zip(meshes[\"iter\"], meshes[\"mesh\"]):\n",
    "    plots[f\"Iteration {i}\"] = {\"point cloud to fit\": point_cloud, \"mesh_progression\": m}\n",
    "\n",
    "\n",
    "plots[\"Final mesh\"] = {\"mesh_progression\": mesh}\n",
    "\n",
    "fig = plot_scene(plots, ncols=4)\n",
    "fig.update_layout(width=1600, height=2400, margin=dict(l=80, r=80, t=20, b=20))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Show losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion\n",
    "In this tutorial, we learned how to load a raw point cloud. We center the point cloud to ensure that we can easily use it with a deep learning optimizer. Then we deformed an initial icosphere onto the raw point cloud. We optimized over the verteces by reducing various losses defined for point clouds and meshes."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "gpuClass": "standard",
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
